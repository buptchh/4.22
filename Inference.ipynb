{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":64.298048,"end_time":"2022-09-20T13:29:10.249114","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-09-20T13:28:05.951066","version":"2.3.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master/')\nsys.path.append('../input/hubmap-coat') \nsys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1/\")\nsys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")\nsys.path.append('/kaggle/input/hubmap-coat/')\n!pip install -qq /kaggle/input/mmdetection/einops-0.4.1-py3-none-any.whl","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-09-20T13:28:13.544260Z","iopub.status.busy":"2022-09-20T13:28:13.543441Z","iopub.status.idle":"2022-09-20T13:28:43.870972Z","shell.execute_reply":"2022-09-20T13:28:43.869736Z"},"papermill":{"duration":30.338015,"end_time":"2022-09-20T13:28:43.873815","exception":false,"start_time":"2022-09-20T13:28:13.535800","status":"completed"},"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os \nimport sys\nimport segmentation_models_pytorch as smp\nimport tifffile as tiff\nimport pandas as pd\nfrom torch import nn\nimport torch\nimport torch.cuda.amp as amp\nimport torch.nn.functional as F\nfrom coat import *\nfrom daformer import *\nfrom helper import *\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:28:43.885490Z","iopub.status.busy":"2022-09-20T13:28:43.884701Z","iopub.status.idle":"2022-09-20T13:28:50.127321Z","shell.execute_reply":"2022-09-20T13:28:50.126194Z"},"papermill":{"duration":6.251344,"end_time":"2022-09-20T13:28:50.130132","exception":false,"start_time":"2022-09-20T13:28:43.878788","status":"completed"},"tags":[]},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"valid_file = '../input/hubmap-organ-segmentation/test.csv'\ntiff_dir   = '../input/hubmap-organ-segmentation/test_images'\n\nvalid_df = pd.read_csv(valid_file)\nvalid_df.loc[:,'img_area']=valid_df['img_height']*valid_df['img_width']\nvalid_df = valid_df.sort_values('img_area').reset_index(drop=True)\n\nimage_size_list  = [1024]\norgan_threshold = {\n    'Hubmap': {\n        'kidney'        : 0.40,\n        'prostate'      : 0.40,\n        'largeintestine': 0.40,\n        'spleen'        : 0.40,\n        'lung'          : 0.10,\n    },\n    'HPA': {\n        'kidney'        : 0.50,\n        'prostate'      : 0.50,\n        'largeintestine': 0.50,\n        'spleen'        : 0.50,\n        'lung'          : 0.10,\n    },\n}\ndata_source =['Hubmap', 'HPA']\norgan = ['kidney', 'prostate', 'largeintestine', 'spleen', 'lung']","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:28:50.141614Z","iopub.status.busy":"2022-09-20T13:28:50.140938Z","iopub.status.idle":"2022-09-20T13:28:50.169326Z","shell.execute_reply":"2022-09-20T13:28:50.168460Z"},"papermill":{"duration":0.036366,"end_time":"2022-09-20T13:28:50.171365","exception":false,"start_time":"2022-09-20T13:28:50.134999","status":"completed"},"tags":[]},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def swa_weight(model,\n              checkpoint_list,\n              weight_list):\n    checkpoints = [torch.load(f)['state_dict'] for f in checkpoint_list]\n    for name, param in model.named_parameters():\n            param.data = sum([ckpt[name] * w for ckpt, w in zip(checkpoints, weight_list)])\n    return model","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:28:50.181912Z","iopub.status.busy":"2022-09-20T13:28:50.181644Z","iopub.status.idle":"2022-09-20T13:28:50.186977Z","shell.execute_reply":"2022-09-20T13:28:50.186056Z"},"papermill":{"duration":0.013118,"end_time":"2022-09-20T13:28:50.189131","exception":false,"start_time":"2022-09-20T13:28:50.176013","status":"completed"},"tags":[]},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_net(Net,encoder,ckpt_list,weight_list):\n    model = Net(encoder=encoder).cuda()\n    model = swa_weight(model,ckpt_list,weight_list)\n    return model","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:28:50.222547Z","iopub.status.busy":"2022-09-20T13:28:50.222278Z","iopub.status.idle":"2022-09-20T13:28:50.227553Z","shell.execute_reply":"2022-09-20T13:28:50.226719Z"},"papermill":{"duration":0.012545,"end_time":"2022-09-20T13:28:50.229320","exception":false,"start_time":"2022-09-20T13:28:50.216775","status":"completed"},"tags":[]},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Net_lite_medium(nn.Module):\n      def __init__(self,encoder,decoder=daformer_conv3x3,   \n                    encoder_cfg={},\n                    decoder_cfg={},\n                    ):  # decoder = daformer_conv3x3,   for coat-medium\n        super(Net_lite_medium, self).__init__()\n        decoder_dim = decoder_cfg.get('decoder_dim', 320)\n\n        # ----\n        self.output_type = ['inference', 'loss']\n\n\n        self.rgb = RGB()\n\n\n\n        self.encoder = encoder\n\n        encoder_dim = self.encoder.embed_dims\n        self.decoder = decoder(\n          encoder_dim=encoder_dim,\n          decoder_dim=decoder_dim,\n        )\n        self.logit = nn.Sequential(\n          nn.Conv2d(decoder_dim, 1, kernel_size=1),\n        )\n        self.aux = nn.ModuleList([\n                nn.Conv2d(decoder_dim, 1, kernel_size=1, padding=0) for i in range(4)\n            ])\n\n\n      def forward(self, batch):\n\n        x = batch['image']\n        num_class = 5\n        x = self.rgb(x)\n        B, C, H, W = x.shape\n        encoder = self.encoder(x)\n        last, decoder = self.decoder(encoder)\n\n        logit = self.logit(last)\n        logit = F.interpolate(logit, size=None, scale_factor=4, mode='bilinear', align_corners=False)\n\n        output = {}\n        if 'loss' in self.output_type:\n          output['bce_loss'] = F.binary_cross_entropy_with_logits(logit,batch['mask'])\n          for i in range(4):\n            output['aux%d_loss'%i] = criterion_aux_loss(self.aux[i](decoder[i]),batch['mask'])\n        if 'inference' in self.output_type:\n          probability_from_logit = torch.sigmoid(logit)\n          output['probability'] = probability_from_logit\n\n        return output","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:28:50.357306Z","iopub.status.busy":"2022-09-20T13:28:50.356783Z","iopub.status.idle":"2022-09-20T13:28:50.367066Z","shell.execute_reply":"2022-09-20T13:28:50.366096Z"},"papermill":{"duration":0.018196,"end_time":"2022-09-20T13:28:50.369153","exception":false,"start_time":"2022-09-20T13:28:50.350957","status":"completed"},"tags":[]},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"checks_v1 = ['../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_score_model_aug2_5level_0_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_loss_model_aug2_5level_0_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_best_dice_score_model_aug2_5level_0_stain_medium33.pth']\nchecks_v2 = ['../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_score_model_aug2_5level_1_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_loss_model_aug2_5level_1_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_best_dice_score_model_aug2_5level_1_stain_medium33.pth']\nchecks_v3 = ['../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_score_model_aug2_5level_2_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_loss_model_aug2_5level_2_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_best_dice_score_model_aug2_5level_2_stain_medium33.pth']\nchecks_v4 = ['../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_score_model_aug2_5level_3_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_loss_model_aug2_5level_3_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_best_dice_score_model_aug2_5level_3_stain_medium33.pth']\nchecks_v5 = ['../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_score_model_aug2_5level_4_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_dice_loss_model_aug2_5level_4_stain_medium33.pth','../input/hubmap-dataset-v2/coat_medium_aug3/coat_nodecoder_best_best_dice_score_model_aug2_5level_4_stain_medium33.pth']\nweights = [0.4,0.3,0.3]\nnet_v1 = load_net(Net_lite_medium,coat_lite_medium(),checks_v1,weights )\nnet_v2 = load_net(Net_lite_medium,coat_lite_medium(),checks_v2,weights )\nnet_v3 = load_net(Net_lite_medium,coat_lite_medium(),checks_v3,weights )\nnet_v4 = load_net(Net_lite_medium,coat_lite_medium(),checks_v4,weights )\nnet_v5 = load_net(Net_lite_medium,coat_lite_medium(),checks_v5,weights )\nall_net = [net_v1,net_v2,net_v3,net_v4,net_v5]","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:28:50.395936Z","iopub.status.busy":"2022-09-20T13:28:50.395682Z","iopub.status.idle":"2022-09-20T13:29:01.128420Z","shell.execute_reply":"2022-09-20T13:29:01.127247Z"},"papermill":{"duration":10.740829,"end_time":"2022-09-20T13:29:01.131175","exception":false,"start_time":"2022-09-20T13:28:50.390346","status":"completed"},"tags":[]},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def do_tta_batch(image, organ):\n    batch = {\n        'image': torch.stack([\n            image,\n            torch.flip(image,dims=[1]),\n            torch.flip(image,dims=[2]),\n        ]),\n        'organ': torch.Tensor(\n            [[organ_to_label[organ]]]*3\n        ).long()\n    return batch","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:29:01.141770Z","iopub.status.busy":"2022-09-20T13:29:01.141471Z","iopub.status.idle":"2022-09-20T13:29:01.147674Z","shell.execute_reply":"2022-09-20T13:29:01.146748Z"},"papermill":{"duration":0.013908,"end_time":"2022-09-20T13:29:01.149873","exception":false,"start_time":"2022-09-20T13:29:01.135965","status":"completed"},"tags":[]},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def undo_tta_batch(probability):\n    probability[0] = probability[0]\n    probability[1] = torch.flip(probability[1],dims=[1])\n    probability[2] = torch.flip(probability[2],dims=[2])\n    probability = probability.mean(0, keepdims=True)\n    probability = probability[0,0].float()\n    return probability\n\ndef rle_decode(rle, height, width , fill=255, dtype=np.uint8):\n    s = rle.split()\n    start, length = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    start -= 1\n    mask = np.zeros(height*width, dtype=dtype)\n    for i, l in zip(start, length):\n        mask[i:i+l] = fill\n    mask = mask.reshape(width,height).T\n    mask = np.ascontiguousarray(mask)\n    return mask","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:29:01.160075Z","iopub.status.busy":"2022-09-20T13:29:01.159813Z","iopub.status.idle":"2022-09-20T13:29:01.167504Z","shell.execute_reply":"2022-09-20T13:29:01.166477Z"},"papermill":{"duration":0.015613,"end_time":"2022-09-20T13:29:01.169933","exception":false,"start_time":"2022-09-20T13:29:01.154320","status":"completed"},"tags":[]},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import tifffile\nimage_size = 768\nresult = []\n\ndef read_tiff(path, scale=None, verbose=0): \n    image = tifffile.imread(path)\n    if len(image.shape) == 5:\n        image = image.squeeze().transpose(1, 2, 0)\n    \n    if verbose:\n        print(f\"[{path}] Image shape: {image.shape}\")\n    \n    if scale:\n        new_size = (image.shape[1] // scale, image.shape[0] // scale)\n        image = cv2.resize(image, new_size)\n        if verbose:\n            print(f\"[{path}] Resized Image shape: {image.shape}\")\n        \n    mx = np.max(image)\n    image = image.astype(np.float32)\n    if mx:\n        image /= mx # scale image to [0, 1]\n    return image\n\n\n\ncount = 0\nfor i,d in valid_df.iterrows():\n    id = d['id']\n    \n    if (d['data_source'] in data_source) and (d['organ'] in organ):\n\n        # read the image from the tiff\n        tiff_file = tiff_dir +'/%d.tiff'%id\n        tiff = read_tiff(tiff_file) \n#         tiff = tiff.astype(np.float32)/255\n        H,W,_ = tiff.shape\n        \n        image = cv2.resize(tiff,dsize=(image_size,image_size),interpolation=cv2.INTER_LINEAR)\n        count += 1\n\n        # create tensor batches\n        image = image_to_tensor(image, 'rgb')\n        batch = { k:v.cuda() for k,v in do_tta_batch(image, d.organ).items() }\n#         batch = {}\n#         batch['image'] = image.cuda()\n\n        # get the masks probabilities from the pretrained model\n        use = 0\n        probability = 0\n        with torch.no_grad():\n            with amp.autocast(enabled = True):\n\n                for n in all_net:\n#                         print(use)\n#                     for n in net:\n                        n.output_type = ['inference']\n                        use += 1\n                        output = n(batch)\n                        probaility = output['probability']\n                        # interpolate - resize to the competition image size\n                        probability += \\\n                            F.interpolate(output['probability'], size=(d.img_height,d.img_width),\n                                          mode='bilinear',align_corners=False, antialias=True )\n\n                probability = undo_tta_batch(probability / use)\n\n        probability = probability.data.cpu().numpy()\n        \n        # use the organ threshold to play with the predictions\n        p = probability>organ_threshold[d.data_source][d.organ]\n        \n#         p = probability\n        \n        # lossless data compression encoding\n        rle = rle_encode(p)\n        \n    else:\n        rle = ''\n\n    result.append({ 'id':id, 'rle':rle, })","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:29:01.197536Z","iopub.status.busy":"2022-09-20T13:29:01.197284Z","iopub.status.idle":"2022-09-20T13:29:07.771044Z","shell.execute_reply":"2022-09-20T13:29:07.770055Z"},"papermill":{"duration":6.582479,"end_time":"2022-09-20T13:29:07.773469","exception":false,"start_time":"2022-09-20T13:29:01.190990","status":"completed"},"tags":[]},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(result)\nsub.to_csv('submission.csv',index=False)\nsub.head()","metadata":{"execution":{"iopub.execute_input":"2022-09-20T13:29:07.785533Z","iopub.status.busy":"2022-09-20T13:29:07.783876Z","iopub.status.idle":"2022-09-20T13:29:07.802500Z","shell.execute_reply":"2022-09-20T13:29:07.801427Z"},"papermill":{"duration":0.02717,"end_time":"2022-09-20T13:29:07.805440","exception":false,"start_time":"2022-09-20T13:29:07.778270","status":"completed"},"tags":[]},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>rle</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10078</td>\n","      <td>369 219 2392 219 4415 219 6438 219 8460 220 10...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id                                                rle\n","0  10078  369 219 2392 219 4415 219 6438 219 8460 220 10..."]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.004364,"end_time":"2022-09-20T13:29:07.814654","exception":false,"start_time":"2022-09-20T13:29:07.810290","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.004301,"end_time":"2022-09-20T13:29:07.823535","exception":false,"start_time":"2022-09-20T13:29:07.819234","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.004552,"end_time":"2022-09-20T13:29:07.832734","exception":false,"start_time":"2022-09-20T13:29:07.828182","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}